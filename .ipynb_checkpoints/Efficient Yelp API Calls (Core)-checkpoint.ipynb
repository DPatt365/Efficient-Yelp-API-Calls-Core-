{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7bef3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dffc4f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yelpapi in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: requests in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (from yelpapi) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (from requests->yelpapi) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (from requests->yelpapi) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (from requests->yelpapi) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (from requests->yelpapi) (1.26.13)\n",
      "Requirement already satisfied: tqdm in /Users/dpatt/anaconda3/envs/dojo-env/lib/python3.9/site-packages (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install yelpapi\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "824903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Credentials\n",
    "with open('/Users/dpatt/.secret/yelp_api.json') as f:   #use your path here!\n",
    "    login = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "04e9c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate YelpAPI Variable\n",
    "yelp_api = YelpAPI(login['api-key'], timeout_s=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de9e428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our API call parameters \n",
    "LOCATION = 'LA,CA'\n",
    "TERM = 'Burritos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "79d90493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/results_in_progress_CA_burritos.json'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying JSON_FILE filename (can include a folder)\n",
    "# include the search terms in the filename\n",
    "JSON_FILE = \"Data/results_in_progress_CA_burritos.json\"\n",
    "JSON_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19cdb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Data/results_in_progress_CA_burritos.json already exists.\n"
     ]
    }
   ],
   "source": [
    "## Check if JSON_FILE exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "## If it does not exist: \n",
    "if file_exists == False:\n",
    "    \n",
    "    ## CREATE ANY NEEDED FOLDERS\n",
    "    # Get the Folder Name only\n",
    "    folder = os.path.dirname(JSON_FILE)\n",
    "    ## If JSON_FILE included a folder:\n",
    "    if len(folder)>0:\n",
    "        # create the folder\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "        \n",
    "    ## INFORM USER AND SAVE EMPTY LIST\n",
    "    print(f'[i] {JSON_FILE} not found. Saving empty list to file.')\n",
    "    \n",
    "    \n",
    "    # save an empty list\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([],f)  \n",
    "# If it exists, inform user\n",
    "else:\n",
    "    print(f\"[i] {JSON_FILE} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88a5142f",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [112], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Load previous results and use len of results for offset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(JSON_FILE,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     previous_results \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## set offset based on previous results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(previous_results)\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93e5a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['businesses', 'total', 'region'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacdfa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51a12b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "results_per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f3c9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import additional packages for controlling our loop\n",
    "import time, math\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e49053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new results with old list with extend and save to file\n",
    "previous_results.extend(results['businesses'])  \n",
    "with open(JSON_FILE,'w') as f:\n",
    "     json.dump(previous_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa75a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c760e8c01d466a8a4a960dcba7be12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "for i in tqdm_notebook(range(n_pages)):\n",
    "    # adds 200 ms pause\n",
    "    time.sleep(.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09468951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6ce912e650441198de162d8c1238d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "YelpAPIError",
     "evalue": "VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mYelpAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(previous_results)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## use n_results as the OFFSET \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43myelp_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTERM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m## append new results and save to file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m previous_results\u001b[38;5;241m.\u001b[39mextend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusinesses\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/site-packages/yelpapi/yelpapi.py:251\u001b[0m, in \u001b[0;36mYelpAPI.search_query\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA valid location (parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or latitude/longitude combination \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    249\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(parameters \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) must be provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEARCH_API_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/site-packages/yelpapi/yelpapi.py:299\u001b[0m, in \u001b[0;36mYelpAPI._query\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Yelp can return one of many different API errors, so check for one of them.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# The Yelp Fusion API does not yet have a complete list of errors, but this is on the TODO list; see\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# https://github.com/Yelp/yelp-fusion/issues/95 for more info.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_json:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YelpAPI\u001b[38;5;241m.\u001b[39mYelpAPIError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    300\u001b[0m                                                response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# we got a good response, so return\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_json\n",
      "\u001b[0;31mYelpAPIError\u001b[0m: VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000."
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    # add a 200ms pause\n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0278fb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## delete file and confirm it no longer exits.\n",
    "os.remove(JSON_FILE)\n",
    "os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9aeefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(JSON_FILE,  delete_if_exists=False):\n",
    "    if file_exists == True:\n",
    "        if delete_if_exists==True:\n",
    "            print(f\"[!] {JSON_FILE} already exists. Deleting previous file...\")\n",
    "            os.remove(JSON_FILE)\n",
    "            create_json_file(JSON_FILE,delete_if_exists=False)\n",
    "        else:\n",
    "            print(f\"[i] {JSON_FILE} already exists.\")\n",
    "                \n",
    "    else:\n",
    "        print(f\"[i] {JSON_FILE} not found. Saving empty list to new file.\")\n",
    "        folder = os.path.dirname(JSON_FILE)\n",
    "        \n",
    "        if len(folder)>0:\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            son.dump([],f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0880d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Data/results_in_progress_CA_burritos.json already exists. Deleting previous file...\n",
      "[i] Data/results_in_progress_CA_burritos.json already exists.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/results_in_progress_CA_burritos.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [113], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m create_json_file(JSON_FILE, delete_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Load previous results and use len of results for offset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mJSON_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     previous_results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m## set offset based on previous results\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/results_in_progress_CA_burritos.json'"
     ]
    }
   ],
   "source": [
    "## Create a new empty json file (exist the previous if it exists)\n",
    "create_json_file(JSON_FILE, delete_if_exists=True)\n",
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')\n",
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "## How many results total?\n",
    "total_results = results['total']\n",
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f5486782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430d0e0a039c4806a60ffde1f31e77ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [104], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook( \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,n_pages\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m## Read in results in progress file and check the length\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(JSON_FILE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m         previous_results \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m## save number of results for to use as offset\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(previous_results)\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    \n",
    "    if (n_results + results_per_page) > 1000:\n",
    "        print('Exceeded 1000 api calls. Stopping loop.')\n",
    "        break\n",
    "    \n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    # display(previous_results)\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    time.sleep(.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final results\n",
    "final_df = pd.read_json(JSON_FILE)\n",
    "display(final_df.head(), final_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a326c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate results\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca30c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate ID's \n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate ids and confirm there are no more duplicates\n",
    "final_df = final_df.drop_duplicates(subset='id')\n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results to a compressed csv\n",
    "final_df.to_csv('Data/final_results_CA_burrito.csv.gz', compression='gzip',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
